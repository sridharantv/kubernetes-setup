setenforce 0
cp /etc/selinux/config /etc/selinux/config.orig

cat << EOF > /etc/selinux/config
# This file controls the state of SELinux on the system.
# SELINUX= can take one of these three values:
#     enforcing - SELinux security policy is enforced.
#     permissive - SELinux prints warnings instead of enforcing.
#     disabled - No SELinux policy is loaded.
SELINUX=disabled
# SELINUXTYPE= can take one of three values:
#     targeted - Targeted processes are protected,
#     minimum - Modification of targeted policy. Only selected processes are protected.
#     mls - Multi Level Security protection.
SELINUXTYPE=targeted
EOF

systemctl stop firewalld
systemctl disable firewalld

mkdir -p \
/etc/pki/tls/kubernetes/k8s/

mkdir -p \
/etc/pki/tls/kubernetes/etcd/ca

chown -R osboxes:osboxes /etc/pki/tls/kubernetes

cd /home/osboxes
tar -zxvf kubernetes-server-linux-amd64.tar.gz
mv -f /home/osboxes/kubernetes/server/bin/kube-apiserver /usr/bin/
mv -f /home/osboxes/kubernetes/server/bin/kube-controller-manager /usr/bin/
mv -f /home/osboxes/kubernetes/server/bin/kube-scheduler /usr/bin/


###########################################
cat << EOF  > /usr/lib/systemd/system/kube-apiserver.service
[Unit]
Description=KUBE-APISERVER 
After=network.target

[Service]
User=osboxes
Restart=on-failure
RestartSec=5s
ExecStart=/usr/bin/kube-apiserver \\
  --advertise-address=`hostname -i` \\
  --etcd-cafile=/etc/pki/tls/kubernetes/etcd/ca/etcd-ca.pem \\
  --etcd-certfile=/etc/pki/tls/kubernetes/k8s/apiserver/client/apiserver-etcd-client.pem \\
  --etcd-keyfile=/etc/pki/tls/kubernetes/k8s/apiserver/client/private/apiserver-etcd-client-key.pem \\
  --etcd-servers=https://192.168.101.138:2379,https://192.168.101.139:2379,https://192.168.101.140:2379 \\
  --bind-address=`hostname -i` \\
  --secure-port=6443 \\
  --tls-cert-file=/etc/pki/tls/kubernetes/k8s/apiserver/server/apiserver-server.pem \\
  --tls-private-key-file=/etc/pki/tls/kubernetes/k8s/apiserver/server/private/apiserver-server-key.pem \\
  --enable-bootstrap-token-auth \\
  --client-ca-file=/etc/pki/tls/kubernetes/k8s/ca/k8s-ca.pem \\
  --allow-privileged \\
  --apiserver-count=3 \\
  --kubelet-certificate-authority=/etc/pki/tls/kubernetes/k8s/ca/k8s-ca.pem \\
  --kubelet-client-certificate=/etc/pki/tls/kubernetes/k8s/apiserver/client/apiserver-kubelet-client.pem \\
  --kubelet-client-key=/etc/pki/tls/kubernetes/k8s/apiserver/client/private/apiserver-kubelet-client-key.pem \\
  --kubelet-https \\
  --service-cluster-ip-range=10.96.0.0/16 \\
  --service-account-key-file=/etc/pki/tls/kubernetes/k8s/sa/sa-pub.pem \\
  --authorization-mode=Node,RBAC \\
  --enable-bootstrap-token-auth \\
  --proxy-client-cert-file=/etc/pki/tls/kubernetes/k8s/admin/client/admin-client.pem \\
  --proxy-client-key-file=/etc/pki/tls/kubernetes/k8s/admin/client/private/admin-client-key.pem
  
Type=notify

[Install]
WantedBy=multi-user.target
EOF

systemctl daemon-reload

systemctl enable kube-apiserver
systemctl stop kube-apiserver
systemctl start kube-apiserver
systemctl status kube-apiserver


############################
haproxy
############################
setenforce 0
cp /etc/selinux/config /etc/selinux/config.orig

cat << EOF > /etc/selinux/config
# This file controls the state of SELinux on the system.
# SELINUX= can take one of these three values:
#     enforcing - SELinux security policy is enforced.
#     permissive - SELinux prints warnings instead of enforcing.
#     disabled - No SELinux policy is loaded.
SELINUX=disabled
# SELINUXTYPE= can take one of three values:
#     targeted - Targeted processes are protected,
#     minimum - Modification of targeted policy. Only selected processes are protected.
#     mls - Multi Level Security protection.
SELINUXTYPE=targeted
EOF

systemctl stop firewalld
systemctl disable firewalld


yum install -y haproxy.x86_64

cp /etc/haproxy/haproxy.cfg /etc/haproxy/haproxy.cfg.orig

cat << EOF > /etc/haproxy/haproxy.cfg
global
   user haproxy
   group haproxy
   daemon
defaults
   log  global
   mode http
   option       httplog
   option       dontlognull
       timeout connect 5000
       timeout client  50000
       timeout server  50000
frontend k8s-api
   bind 0.0.0.0:443
   mode tcp
   option tcplog
   default_backend k8s-api
backend k8s-api
   mode tcp
   option tcplog
   option tcp-check
   balance roundrobin
   default-server inter 10s downinter 5s rise 2 fall 2 slowstart 60s maxconn 250 maxqueue 256 weight 100
       server apiserver1 192.168.101.141:6443 check
       server apiserver2 192.168.101.142:6443 check
       server apiserver3 192.168.101.143:6443 check
EOF

systemctl enable haproxy
systemctl restart haproxy
systemctl status haproxy


###########
mv -f /home/osboxes/kubernetes/server/bin/kubectl /usr/bin/

mkdir -p /etc/kubernetes/manifests

KUBECONFIG=~/.kube/config kubectl config set-cluster default-cluster --server=https://192.168.101.144:443 --certificate-authority /etc/pki/tls/kubernetes/k8s/ca/k8s-ca.pem --embed-certs

KUBECONFIG=~/.kube/config kubectl config set-credentials default-admin --client-key /etc/pki/tls/kubernetes/k8s/admin/client/private/admin-client-key.pem --client-certificate /etc/pki/tls/kubernetes/k8s/admin/client/admin-client.pem --embed-certs

KUBECONFIG=~/.kube/config kubectl config set-context default-system --cluster default-cluster --user default-admin

KUBECONFIG=~/.kube/config kubectl config use-context default-system

chmod 644 ~/.kube/config

=======

cat << EOF > /tmp/bootstrap-token-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  # Name MUST be of form "bootstrap-token-<token id>"
  name: bootstrap-token-07401b
  namespace: kube-system

# Type MUST be 'bootstrap.kubernetes.io/token'
type: bootstrap.kubernetes.io/token
stringData:
  # Human readable description. Optional.
  description: "The default bootstrap token generated by 'kubeadm init'."

  # Token ID and secret. Required.
  token-id: 07401b
  token-secret: f395accd246ae52d

  # Allowed usages.
  usage-bootstrap-authentication: "true"
  usage-bootstrap-signing: "true"

  # Extra groups to authenticate the token as. Must start with "system:bootstrappers:"
  auth-extra-groups: system:bootstrappers:worker
EOF

cat << EOF > /tmp/create-csrs-for-bootstrapping.yaml
# enable bootstrapping nodes to create CSR
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: create-csrs-for-bootstrapping
subjects:
- kind: Group
  name: system:bootstrappers
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: ClusterRole
  name: system:node-bootstrapper
  apiGroup: rbac.authorization.k8s.io
EOF

cat << EOF > /tmp/auto-approve-csrs-for-group.yaml
# Approve all CSRs for the group "system:bootstrappers"
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: auto-approve-csrs-for-group
subjects:
- kind: Group
  name: system:bootstrappers
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: ClusterRole
  name: system:certificates.k8s.io:certificatesigningrequests:nodeclient
  apiGroup: rbac.authorization.k8s.io
EOF

cat << EOF > /tmp/auto-approve-renewals-for-nodes.yaml
# Approve renewal CSRs for the group "system:nodes"
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: auto-approve-renewals-for-nodes
subjects:
- kind: Group
  name: system:nodes
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: ClusterRole
  name: system:certificates.k8s.io:certificatesigningrequests:selfnodeclient
  apiGroup: rbac.authorization.k8s.io
EOF

kubectl apply -f /tmp/bootstrap-token-secret.yaml
kubectl apply -f /tmp/create-csrs-for-bootstrapping.yaml
kubectl apply -f /tmp/auto-approve-csrs-for-group.yaml
kubectl apply -f /tmp/auto-approve-renewals-for-nodes.yaml



